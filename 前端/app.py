import os
import re
import json
import math
import time
import xml.etree.ElementTree as ET
from collections import defaultdict, deque
from datetime import datetime, timedelta
from decimal import Decimal, ROUND_HALF_UP
from email.utils import parsedate_to_datetime
from functools import lru_cache
from statistics import median
from typing import Optional
from urllib.parse import quote_plus
import html as py_html  # ä¿ç•™ä½ åŸæœ¬ä½¿ç”¨çš„åˆ¥å

import requests
import pandas as pd
import yfinance as yf
from dotenv import load_dotenv
from flask import (
    Flask,
    render_template,
    request,
    jsonify,
    redirect,
    url_for,
    Response,
    stream_with_context,
)
from flask_cors import CORS
from flask_login import (
    LoginManager,
    login_user,
    login_required,
    logout_user,
    current_user,
    UserMixin,
)
from flask_sqlalchemy import SQLAlchemy  # ä½ é›–ç„¶ç”¨ models.dbï¼Œä½†ä¿ç•™æ²’é—œä¿‚
from werkzeug.security import generate_password_hash, check_password_hash
from openai import OpenAI
import openai
from FinMind.data import DataLoader
from models import db, User, Trade, Result


# è¼‰å…¥ .env æª”æ¡ˆ
load_dotenv()

api_key = os.getenv("OPENAI_API_KEY")
finmind_token = os.getenv("FINMIND_TOKEN")

client = OpenAI(api_key=api_key)

# åˆå§‹åŒ– FinMind å®¢æˆ¶ç«¯
api = DataLoader()
api.login_by_token(api_token=finmind_token)

# åˆå§‹åŒ– Flask æ‡‰ç”¨ç¨‹å¼
app = Flask(
    __name__,
    static_folder="static",         # æ˜ç¢ºæŒ‡å®š static è·¯å¾‘
    template_folder="templates"     # æ˜ç¢ºæŒ‡å®š HTML æ¨¡æ¿è³‡æ–™å¤¾
)
CORS(app)

# è¨­å®šç’°å¢ƒè®Šæ•¸
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'default-secret-key')

MYSQL_USER = os.getenv("MYSQL_USER")
MYSQL_PASSWORD = os.getenv("MYSQL_PASSWORD")
MYSQL_HOST = os.getenv("MYSQL_HOST")
MYSQL_PORT = os.getenv("MYSQL_PORT", "3306")
MYSQL_DATABASE = os.getenv("MYSQL_DATABASE")

# è¨­å®š MySQL é€£ç·š
app.config['SQLALCHEMY_DATABASE_URI'] = (
    f"mysql+mysqlconnector://{MYSQL_USER}:{MYSQL_PASSWORD}@{MYSQL_HOST}:{MYSQL_PORT}/{MYSQL_DATABASE}"
)
app.config['SQLALCHEMY_TRACK_MODIFICATIONS'] = False
app.config['INITIAL_BALANCE'] = 10000000

# åˆå§‹åŒ–è³‡æ–™åº«ï¼ˆä½¿ç”¨ models.py çš„ db å¯¦ä¾‹ï¼‰
db.init_app(app)

# åˆå§‹åŒ–ç™»å…¥ç®¡ç†
login_manager = LoginManager()
login_manager.login_view = 'login'
login_manager.init_app(app)

@login_manager.user_loader
def load_user(user_id):
    return User.query.get(int(user_id))

# Homepage
@app.route("/")
@login_required
def index():
    return render_template("index.html")

def home():
    return render_template('ai.html')

# Price history
@app.route("/history")
@login_required
def get_history():
    
    ticker = request.args.get("ticker", "").strip()
    if not ticker:
        return jsonify(success=False, message="ç¼ºå°‘è‚¡ç¥¨ä»£ç¢¼")

    try:
        # è©¦è‘—ç”¨ .TWï¼Œè‹¥ 404 å°±ç”¨ .TWO
        try:
            data = yf.Ticker(f"{ticker}.TW").history(period="1mo")
            if data.empty:
                raise Exception("empty")
        except:
            data = yf.Ticker(f"{ticker}.TWO").history(period="1mo")
            if data.empty:
                raise Exception("empty")

        data = data.reset_index()[["Date", "Close"]].dropna()
        data["Date"] = pd.to_datetime(data["Date"]).dt.strftime("%Y-%m-%d")

        result = data.to_dict(orient="records")
        return jsonify(success=True, data=result)

    except Exception as e:
        return jsonify(success=False, message=f"æŸ¥è©¢æ­·å²åƒ¹æ ¼å¤±æ•—ï¼š{str(e)}")




@app.route("/price")
@login_required
def get_price():
    ticker = request.args.get("ticker", "").strip()
    if not ticker.isdigit():
        return jsonify(success=False, message="è‚¡ç¥¨ä»£ç¢¼æ‡‰ç‚ºæ•¸å­—")

    # å˜—è©¦å¾ TWSE æŠ“å–
    try:
        url = f"https://mis.twse.com.tw/stock/api/getStockInfo.jsp?ex_ch=tse_{ticker}.tw"
        res = requests.get(url)
        data = res.json()
        msg_array = data.get("msgArray", [])
        if msg_array and "z" in msg_array[0]:
            z = msg_array[0]["z"]
            if z and z != "-":
                price = float(z)
                return jsonify(success=True, price=price)
    except Exception as e:
        print(f"âš ï¸ TWSE æŠ“å–å¤±æ•—ï¼š{e}")

    # æ”¹ç”¨ Yahoo æŠ“ï¼ˆé †åºå…ˆ TWO å† TWï¼‰
    for suffix in [".TWO", ".TW"]:
        try:
            stock = yf.Ticker(ticker + suffix)
            hist = stock.history(period="1d")
            if not hist.empty:
                price = float(hist["Close"].iloc[-1])
                return jsonify(success=True, price=price)
        except Exception as e:
            print(f"âš ï¸ Yahoo æŠ“ {ticker + suffix} å¤±æ•—ï¼š{e}")

    return jsonify(success=False, message="æŸ¥ç„¡åƒ¹æ ¼è³‡æ–™ï¼ˆTWSE & Yahooï¼‰")




        
# Buy stock
@app.route("/buy", methods=["POST"])
@login_required
def buy():
    data = request.get_json()
    ticker = data.get("ticker")
    quantity = int(data.get("quantity", 0))  # è‚¡æ•¸
    price = float(data.get("price", 0))
    mode = data.get("mode", "æ•´è‚¡")  # å¦‚æœå¾ JS å‚³ä¾†

    if not ticker or quantity <= 0 or price <= 0:
        return jsonify(success=False, message="è³‡æ–™éŒ¯èª¤")

    total_cost = quantity * price

    user = User.query.get(current_user.id)
    if user is None:
        return jsonify(success=False, message="æ‰¾ä¸åˆ°ä½¿ç”¨è€…")

    if total_cost > user.balance:
        return jsonify(success=False, message="é¤˜é¡ä¸è¶³ï¼Œç„¡æ³•å®Œæˆäº¤æ˜“")

    new_trade = Trade(
        user_id=user.id,
        ticker=ticker,
        quantity=quantity,
        price=price,
        trade_type="è²·å…¥",
        mode=mode,
        created_at=datetime.utcnow()
    )

    user.balance -= total_cost
    db.session.add(new_trade)
    db.session.commit()

    return jsonify(success=True)

# Sell stock
@app.route("/sell", methods=["POST"])
@login_required
def sell():
    data = request.get_json()
    ticker = data.get("ticker")
    quantity = int(data.get("quantity", 0))
    price = float(data.get("price", 0))
    mode = data.get("mode", "æ•´è‚¡")

    if not ticker or quantity <= 0 or price <= 0:
        return jsonify(success=False, message="è³‡æ–™éŒ¯èª¤")

    user = User.query.get(current_user.id)

    # è¨ˆç®—è©²è‚¡ç¥¨ç¸½æŒæœ‰è‚¡æ•¸ï¼ˆæ•´è‚¡ + é›¶è‚¡ï¼‰
    all_trades = Trade.query.filter_by(user_id=user.id, ticker=ticker).all()
    total_qty = sum(t.quantity if t.trade_type == "è²·å…¥" else -t.quantity for t in all_trades)

    if quantity > total_qty:
        return jsonify(success=False, message="âŒ æŒè‚¡ä¸è¶³ï¼Œç„¡æ³•è³£å‡º")

    total_gain = quantity * price

    new_trade = Trade(
        user_id=user.id,
        ticker=ticker,
        quantity=quantity,
        price=price,
        trade_type="è³£å‡º",
        mode=mode,
        created_at=datetime.utcnow()
    )

    user.balance += total_gain

    db.session.add(new_trade)
    db.session.commit()

    return jsonify(success=True)


@app.route('/trade', methods=['POST'])
@login_required
def trade():
    data = request.form  # âœ… æ­£ç¢ºçš„åœ°æ–¹

    ticker = data.get('ticker')
    quantity = int(data.get('quantity', 0))
    price = float(data.get('price', 0))
    trade_type = data.get('trade_type')  # "è²·å…¥" or "è³£å‡º"
    mode = data.get('mode', "é›¶è‚¡")  # é è¨­ç‚ºé›¶è‚¡æ¨¡å¼

    if not ticker or quantity <= 0 or price <= 0 or trade_type not in ["è²·å…¥", "è³£å‡º"]:
        return jsonify({"success": False, "message": "åƒæ•¸éŒ¯èª¤"}), 400

    user = User.query.get(current_user.id)
    cost = quantity * price

    if trade_type == "è²·å…¥":
        if user.balance < cost:
            return jsonify({"success": False, "message": "é¤˜é¡ä¸è¶³"}), 400
        user.balance -= cost

    elif trade_type == "è³£å‡º":
        holdings = db.session.query(
            db.func.sum(Trade.quantity)
        ).filter_by(user_id=user.id, ticker=ticker).scalar() or 0
        if holdings < quantity:
            return jsonify({"success": False, "message": "æŒè‚¡ä¸è¶³"}), 400
        user.balance += cost

    new_trade = Trade(
        user_id=user.id,
        ticker=ticker,
        quantity=quantity,
        price=price,
        trade_type=trade_type,
        mode=mode,
        created_at=datetime.utcnow()
    )
    db.session.add(new_trade)
    db.session.commit()

    return jsonify({"success": True, "message": f"{mode}äº¤æ˜“å®Œæˆ"})



# Portfolio API
@app.route("/api/portfolio")
@login_required
def api_portfolio():
    trades = Trade.query.filter_by(user_id=current_user.id).order_by(Trade.created_at).all()
    balance = Decimal(app.config["INITIAL_BALANCE"])
    
    portfolio = defaultdict(lambda: {
        "lots": deque(),   # æ¯ç­†è²·å…¥è¨˜éŒ„ (quantity, price)
        "qty": Decimal("0"),
    })

    for t in trades:
        qty = Decimal(t.quantity)
        price = Decimal(str(t.price))  # é¿å… float ç²¾åº¦å•é¡Œ
        cost = qty * price

        if t.trade_type == "è²·å…¥":
            balance -= cost
            portfolio[t.ticker]["lots"].append((qty, price))
            portfolio[t.ticker]["qty"] += qty

        elif t.trade_type == "è³£å‡º":
            balance += cost
            remaining = qty
            lots = portfolio[t.ticker]["lots"]
            portfolio[t.ticker]["qty"] -= qty

            # FIFO: å…ˆæŠŠæœ€æ—©è²·å…¥çš„æ‰£æ‰
            while remaining > 0 and lots:
                lot_qty, lot_price = lots[0]
                if lot_qty > remaining:
                    lots[0] = (lot_qty - remaining, lot_price)
                    remaining = Decimal("0")
                else:
                    remaining -= lot_qty
                    lots.popleft()

            # è‹¥å·²å…¨éƒ¨è³£å…‰ï¼Œæ¸…é™¤è³‡æ–™
            if portfolio[t.ticker]["qty"] <= 0:
                portfolio[t.ticker]["qty"] = Decimal("0")
                portfolio[t.ticker]["lots"].clear()

    result = {
        "balance": float(balance.quantize(Decimal("0.01"), rounding=ROUND_HALF_UP)),
        "portfolio": []
    }

    for ticker, data in portfolio.items():
        total_qty = data["qty"]
        if total_qty == 0:
            continue
        total_cost = sum(q * p for q, p in data["lots"])
        avg_cost = total_cost / total_qty
        result["portfolio"].append({
            "ticker": ticker,
            "quantity": float(total_qty),
            "costAvg": float(avg_cost.quantize(Decimal("0.01"), rounding=ROUND_HALF_UP))
        })

    return jsonify(result)

@app.route("/update-total-assets", methods=["POST"])
@login_required
def update_total_assets():
    data = request.get_json()
    total_assets = data.get("totalAssets")

    if total_assets is None:
        return jsonify(success=False, message="ç¼ºå°‘ç¸½è³‡ç”¢")

    user = User.query.get(current_user.id)
    user.total_assets = total_assets
    db.session.commit()

    return jsonify(success=True)


def build_ranking_data():
    """
    å›å‚³å·²æ’åºçš„ [(username, total_asset), ...]ï¼ˆé«˜â†’ä½ï¼‰ã€‚
    ç›´æ¥æ²¿ç”¨ä½  /ranking å…§çš„è¨ˆç®—é‚è¼¯ã€‚
    """
    import requests
    import yfinance as yf

    def get_stock_price(ticker):
        # 1) å…ˆè©¦ TWSE
        try:
            url = f"https://mis.twse.com.tw/stock/api/getStockInfo.jsp?ex_ch=tse_{ticker}.tw"
            res = requests.get(url, timeout=3)
            data = res.json()
            msg_array = data.get("msgArray", [])
            if msg_array:
                z = msg_array[0].get("z")
                if z and z != "-":
                    return float(z)
        except Exception as e:
            print(f"âš ï¸ TWSE æŠ“ {ticker} åƒ¹æ ¼å¤±æ•—ï¼š{e}")

        # 2) æ”¹ç”¨ Yahoo (TW / TWO)
        for suffix in [".TWO", ".TW"]:
            try:
                stock = yf.Ticker(ticker + suffix)
                hist = stock.history(period="5d")
                if not hist.empty:
                    close_prices = hist["Close"].dropna()
                    if not close_prices.empty:
                        return float(close_prices.iloc[-1])
            except Exception as e:
                print(f"âš ï¸ Yahoo æŠ“ {ticker + suffix} å¤±æ•—ï¼š{e}")

        print(f"âŒ {ticker} å®Œå…¨æŠ“ä¸åˆ°åƒ¹æ ¼")
        return 0.0

    users = User.query.all()
    ranking_data = []

    for user in users:
        cash = user.balance
        trades = Trade.query.filter_by(user_id=user.id).all()

        holdings = {}
        for trade in trades:
            qty = trade.quantity if trade.trade_type in ["è²·å…¥", "buy"] else -trade.quantity
            holdings[trade.ticker] = holdings.get(trade.ticker, 0) + qty

        total_stock_value = 0.0
        for ticker, qty in holdings.items():
            if qty > 0:
                price = get_stock_price(ticker)
                total_stock_value += price * qty

        total_asset = round(cash + total_stock_value, 2)
        ranking_data.append((user.username, total_asset))

    ranking_data.sort(key=lambda x: x[1], reverse=True)
    return ranking_data

# âœ… ä¿æŒä½ åŸæœ‰çš„ /rankingï¼ˆæ”¹æˆå‘¼å«å…±ç”¨å‡½å¼ï¼‰
@app.route("/ranking")
@login_required
def ranking():
    ranking_data = build_ranking_data()
    return render_template("ranking.html", ranking_data=ranking_data)

# âœ… æ–°å¢ï¼šé¦–é æ‹¿ã€Œç›®å‰ä½¿ç”¨è€…åæ¬¡ / ç¸½äººæ•¸ã€çš„ API
@app.route("/api/user-rank")
@login_required
def api_user_rank():
    ranking_data = build_ranking_data()
    total = len(ranking_data)
    rank = next((i + 1 for i, (uname, _) in enumerate(ranking_data)
                 if uname == current_user.username), None)
    my_assets = next((assets for uname, assets in ranking_data
                      if uname == current_user.username), None)
    return jsonify(success=True, rank=rank, total=total, assets=my_assets)




# Quiz with database save
@app.route("/quiz", methods=["GET", "POST"])
@login_required
def quiz():
    if request.method == "POST":
        q1 = int(request.form.get("q1", 0))
        q2 = int(request.form.get("q2", 0))
        q3 = int(request.form.get("q3", 0))
        q4 = int(request.form.get("q4", 0))
        q5 = int(request.form.get("q5", 0))
        score = q1 + q2 + q3 + q4 + q5

        if score <= 3:
            style = "ç©©å¥å‹"
            suggestion = "å»ºè­°åˆ†æ•£æŠ•è³‡æ–¼ä½é¢¨éšªè³‡ç”¢ï¼Œå¦‚å‚µåˆ¸æˆ–å¤§å‹è—ç±Œè‚¡ã€‚"
        elif score <= 7:
            style = "æˆé•·å‹"
            suggestion = "å¯è€ƒæ…®é…ç½®éƒ¨åˆ†è³‡é‡‘æ–¼æˆé•·å‹è‚¡ç¥¨æˆ–ETFï¼Œè¿½æ±‚è³‡æœ¬å¢é•·ã€‚"
        else:
            style = "ç©æ¥µå‹"
            suggestion = "å¯æ‰¿æ“”è¼ƒé«˜é¢¨éšªï¼Œå»ºè­°é…ç½®æ–°èˆˆå¸‚å ´æˆ–é«˜æ³¢å‹•æ€§è³‡ç”¢ï¼Œä½†ä»éœ€æ³¨æ„é¢¨éšªæ§ç®¡ã€‚"

        # âœ… å¯«å…¥è³‡æ–™åº«
        result = Result(
            user_id=current_user.id,
            score=score,
            style=style,
            suggestion=suggestion,
            created_at=datetime.utcnow()
        )
        db.session.add(result)
        db.session.commit()

        return render_template("result.html", style=style, advice=suggestion)

    return render_template("quiz.html")


@app.route("/results")
@login_required
def results():
    filter_style = request.args.get("style", "å…¨éƒ¨")
    if filter_style == "å…¨éƒ¨":
        filtered_results = Result.query.all()
    else:
        filtered_results = Result.query.filter_by(style=filter_style).all()

    style_counts = {
        "ç©©å¥å‹": Result.query.filter_by(style="ç©©å¥å‹").count(),
        "æˆé•·å‹": Result.query.filter_by(style="æˆé•·å‹").count(),
        "ç©æ¥µå‹": Result.query.filter_by(style="ç©æ¥µå‹").count()
    }
    total = Result.query.count()

    return render_template("results.html", total=total,
                           style_counts=style_counts,
                           results=filtered_results,
                           filter_style=filter_style)

# User Registration
@app.route("/register", methods=["GET", "POST"])
def register():
    if request.method == "POST":
        username = request.form.get("username")
        password = request.form.get("password")
        if User.query.filter_by(username=username).first():
            return 'å¸³è™Ÿå·²å­˜åœ¨'
        new_user = User(
            username=username,
            password=generate_password_hash(password, method='pbkdf2:sha256')
        )
        db.session.add(new_user)
        db.session.commit()
        return redirect("/login")
    return render_template("register.html")

# User Login
@app.route("/login", methods=["GET", "POST"])
def login():
    if request.method == "POST":
        username = request.form.get("username")
        password = request.form.get("password")
        user = User.query.filter_by(username=username).first()
        if user and check_password_hash(user.password, password):
            login_user(user)
            return redirect("/")
        return "ç™»å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥å¸³è™Ÿå¯†ç¢¼"
    return render_template("login.html")

# Logout
@app.route("/logout")
@login_required
def logout():
    logout_user()
    return redirect("/login")

@app.route("/trades")
@login_required
def trades():
    trade_records = Trade.query.filter_by(user_id=current_user.id).order_by(Trade.created_at.desc()).all()
    return render_template("trades.html", trades=trade_records)

# trading view
@app.route("/api/market_type")
def get_market_type():
    ticker = request.args.get("ticker", "").strip()
    if not ticker.isdigit() or len(ticker) != 4:
        return jsonify(success=False, message="è‚¡ç¥¨ä»£ç¢¼æ ¼å¼éŒ¯èª¤")

    try:
        url = f"https://mis.twse.com.tw/stock/api/getStockInfo.jsp?ex_ch=tse_{ticker}.tw|otc_{ticker}.tw"
        res = requests.get(url)
        data = res.json().get("msgArray", [])

        for stock in data:
            if stock["c"] == ticker:
                market = stock["ex"]  # æœƒæ˜¯ 'tse' æˆ– 'otc'
                return jsonify(success=True, market=market.upper())
        return jsonify(success=False, message="æŸ¥ç„¡æ­¤è‚¡ç¥¨ä»£ç¢¼")
    except Exception as e:
        return jsonify(success=False, message=f"æŸ¥è©¢å¤±æ•—ï¼š{str(e)}")

#ai
@app.route("/ai.html")
def ai_page():
    return render_template("ai.html")

load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")
finmind_token = os.getenv("FINMIND_TOKEN")

# åˆå§‹åŒ– FinMind ä¸¦å–å¾—å…¬å¸åˆ—è¡¨ä¸€æ¬¡ï¼ˆå¯å¿«å–ï¼‰
api = DataLoader()
api.login_by_token(api_token=finmind_token)
stock_info_df = api.taiwan_stock_info()

# æ ¹æ“šè¼¸å…¥æ‰¾å‡ºè‚¡ç¥¨ä»£è™Ÿèˆ‡å…¬å¸åç¨±
def find_ticker_by_company_name(user_input: str):
    for _, row in stock_info_df.iterrows():
        if row["stock_name"] in user_input or row["stock_id"] in user_input:
            return row["stock_id"], row["stock_name"]
    return None, None

# åˆå§‹åŒ– FinMind ä¸¦å–å¾—å…¬å¸åˆ—è¡¨ä¸€æ¬¡ï¼ˆå¯å¿«å–ï¼‰
api = DataLoader()
api.login_by_token(api_token=finmind_token)
stock_info_df = api.taiwan_stock_info()

# æ ¹æ“šè¼¸å…¥æ‰¾å‡ºè‚¡ç¥¨ä»£è™Ÿèˆ‡å…¬å¸åç¨±
def find_ticker_by_company_name(user_input: str):
    for _, row in stock_info_df.iterrows():
        if row["stock_name"] in user_input or row["stock_id"] in user_input:
            return row["stock_id"], row["stock_name"]
    return None, None

@app.route("/ask-ai", methods=["POST"])
def ask_ai():
    data = request.json
    user_input = data.get("question", "").strip()
    mode = data.get("type", "analysis")

    if not user_input:
        return Response("â—ï¸è«‹è¼¸å…¥å•é¡Œ", mimetype='text/plain')

    def generate(user_input, mode):
        yield "ğŸ’¬ å›ç­”ï¼š\n\n"

        model = "gpt-4"
        prompt = ""
        system_role = ""

        # å˜—è©¦æ‰¾å…¬å¸è³‡è¨Š
        ticker, company_name = find_ticker_by_company_name(user_input)

        if mode == "analysis":
            system_role = "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°è‚¡æŠ•è³‡åˆ†æå¸«ï¼Œè«‹çµ¦å‡ºå°ˆæ¥­ä¸”å¯¦ç”¨çš„å»ºè­°ã€‚"

            if ticker:
                try:
                    today = datetime.today()
                    start_date = (today - timedelta(days=14)).strftime("%Y-%m-%d")
                    end_date = today.strftime("%Y-%m-%d")
                    df = api.taiwan_stock_daily(stock_id=ticker, start_date=start_date, end_date=end_date)
                    df = df[df["close"].notna()].sort_values("date")

                    if len(df) >= 2:
                        start_price = df.iloc[-2]["close"]
                        end_price = df.iloc[-1]["close"]
                        pct = ((end_price - start_price) / start_price) * 100
                        stock_summary = f"è³‡æ–™æ‘˜è¦ï¼š{company_name}ï¼ˆ{ticker}ï¼‰è¿‘å…©å€‹äº¤æ˜“æ—¥è‚¡åƒ¹å¾ {start_price:.2f} å…ƒè®Šå‹•è‡³ {end_price:.2f} å…ƒï¼Œæ¼²è·Œå¹…ç‚º {pct:.2f}%ã€‚"
                    else:
                        stock_summary = f"âš ï¸ æŸ¥ç„¡è¶³å¤ çš„ {company_name}ï¼ˆ{ticker}ï¼‰è‚¡åƒ¹è³‡æ–™ã€‚"
                except Exception as e:
                    stock_summary = f"âš ï¸ ç„¡æ³•å–å¾—è‚¡åƒ¹è³‡æ–™ï¼š{str(e)}"
            else:
                stock_summary = "âš ï¸ ç„¡æ³•è¾¨è­˜å…¬å¸åç¨±æˆ–è‚¡ç¥¨ä»£ç¢¼ã€‚"

            yield stock_summary + "\n\n"

            prompt = f"""{stock_summary}
ä½¿ç”¨è€…å•é¡Œï¼šã€Œ{user_input}ã€
è«‹æ ¹æ“šä¸Šè¿°è³‡æ–™åˆ†æè©²å…¬å¸è¿‘æœŸè¡¨ç¾ï¼Œæä¾›å…·é«”æŠ•è³‡å»ºè­°ã€‚"""

        else:  # mode == future
            system_role = "ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„å°ç£è‚¡ç¥¨é¡§å•ï¼Œæ“…é•·åˆ†æç”¢æ¥­è¶¨å‹¢èˆ‡ä¼æ¥­é•·æœŸç™¼å±•æ½›åŠ›ï¼Œè«‹ç”¨é•·æœŸè¦–è§’çµ¦å‡ºå»ºè­°ã€‚"

            if ticker:
                company_intro = f"å…¬å¸åç¨±ï¼š{company_name}ï¼ˆ{ticker}ï¼‰\n"
                user_input = f"{company_name}ï¼ˆ{ticker}ï¼‰çš„æœªä¾†ç™¼å±•"
            else:
                company_intro = ""

            prompt = f"""{company_intro}ä½¿ç”¨è€…å•é¡Œï¼šã€Œ{user_input}ã€
è«‹ä»¥é•·æœŸï¼ˆ3ï½5 å¹´ï¼‰æŠ•è³‡è¦–è§’ï¼Œæ ¹æ“šè©²å…¬å¸æ‰€è™•ç”¢æ¥­çš„æœªä¾†è¶¨å‹¢ã€å…¨çƒç’°å¢ƒã€æŠ€è¡“å‰µæ–°èˆ‡ç«¶çˆ­åŠ›ï¼Œæä¾›å®Œæ•´ã€æ¸…æ™°çš„å±•æœ›èˆ‡ç­–ç•¥å»ºè­°ã€‚"""

        try:
            client = openai.OpenAI()
            stream = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": system_role},
                    {"role": "user", "content": prompt}
                ],
                stream=True
            )

            for chunk in stream:
                content = chunk.choices[0].delta.content
                if content:
                    yield content

        except Exception as e:
            yield f"\nâŒ GPT å›è¦†å¤±æ•—ï¼š{str(e)}"

    return Response(stream_with_context(generate(user_input, mode)), mimetype="text/plain")


# ===== é¢¨éšªé—œéµè© =====
NEGATIVE_KWS = ["åœå·¥","æ¸›ç”¢","è™§æ","èª¿é™è©•ç­‰","è³£è¶…","è£å“¡","ç¨…å‹™","é•è¦","ç½°æ¬¾","ç«ç½","çˆ†ç‚¸","åœé›»","è·³ç¥¨","å€’é–‰","æ¸›è³‡","è­¦ç¤º","è™•åˆ†","ä¸‹ä¿®","è§£é›‡"]
POSITIVE_KWS = ["æ“´ç”¢","ä¸Šä¿®","è²·è¶…","å¾—æ¨™","åˆä½œ","ä½µè³¼","å‰µé«˜","å‰µæ–°","ç²åˆ©æˆé•·","èªè³¼","å›è³¼","å¢è³‡","æ¼²åœ","åˆ©å¤š","å±•æœ›æ­£é¢"]

def _label_risk(text: str) -> str:
    t = (text or "").strip()
    if any(k in t for k in NEGATIVE_KWS): return "negative"
    if any(k in t for k in POSITIVE_KWS): return "positive"
    return "neutral"

def _maybe_get_name_by_code(q: str) -> Optional[str]:
    q = (q or "").strip()
    if q.isdigit() and len(q) in (4, 5):
        row = stock_info_df[stock_info_df["stock_id"] == q]
        if not row.empty:
            return str(row.iloc[0]["stock_name"])
    return None

# ===== Google News RSS å‚™æ´ï¼ˆå…å®‰è£ç¬¬ä¸‰æ–¹å¥—ä»¶ï¼‰ =====
def _fetch_google_news_rss(keyword: str, hours: int = 48, limit: int = 50):
    """
    å¾ Google News RSS æŠ“é—œéµå­—æ–°èï¼ˆå°ç£ï¼ç¹ä¸­ï¼‰
    å›å‚³ list[dict]: {type, title, source, time, url, risk}
    """
    base = "https://news.google.com/rss/search"
    url = f"{base}?q={quote_plus(keyword)}&hl=zh-TW&gl=TW&ceid=TW:zh-Hant"
    headers = {
        "User-Agent": "Mozilla/5.0 (compatible; NewsFetcher/1.0; +https://example.com)"
    }
    try:
        resp = requests.get(url, timeout=10, headers=headers)
        if resp.status_code != 200 or not resp.text:
            return []
        root = ET.fromstring(resp.text)
        channel = root.find("channel")
        if channel is None:
            return []

        cutoff = datetime.now() - timedelta(hours=hours)
        out = []
        for item in channel.findall("item"):
            title_raw = (item.findtext("title") or "").strip()
            link = (item.findtext("link") or "").strip()
            # å„ªå…ˆ DC:dateï¼Œå…¶æ¬¡ pubDate
            pub_date_str = (item.findtext("{http://purl.org/dc/elements/1.1/}date")
                            or item.findtext("pubDate") or "").strip()

            # è§£ææ™‚é–“ï¼ˆç›¡åŠ›è€Œç‚ºï¼‰
            keep = True
            try:
                dt = parsedate_to_datetime(pub_date_str) if pub_date_str else None
                if dt and dt.tzinfo:
                    dt = dt.astimezone(tz=None).replace(tzinfo=None)
                if dt and dt < cutoff:
                    keep = False
            except Exception:
                pass
            if not keep:
                continue

            # æ‹†å‡ºä¾†æºï¼šã€Œæ¨™é¡Œ - ä¾†æºã€æ ¼å¼å¸¸è¦‹
            source = ""
            title = title_raw
            if " - " in title_raw:
                *tparts, src = title_raw.split(" - ")
                title = " - ".join(tparts).strip()
                source = src.strip()

            # ç§»é™¤ HTML å¯¦é«”
            title = py_html.unescape(title)

            out.append({
                "type": "news",
                "title": title,
                "source": source or "Google News",
                "time": pub_date_str or datetime.now().strftime("%Y-%m-%d %H:%M"),
                "url": link,
                "risk": _label_risk(title),
            })
            if len(out) >= limit:
                break
        return out
    except Exception as e:
        print(f"[rss] fetch error: {e}")
        return []

# ===== FinMind æŠ“æ–°èï¼ˆå¤šè·¯å¾‘å˜—è©¦ï¼‰ =====
def _try_fetch_news(code: Optional[str], keyword: Optional[str],
                    start_date: str, end_date: str, debug_log: list):
    import pandas as pd
    frames = []

    # 1) stock_id + start/end
    if code:
        try:
            df = api.taiwan_stock_news(stock_id=code, start_date=start_date, end_date=end_date)
            debug_log.append(f"news(stock_id,start/end): {len(df) if df is not None else 'None'}")
            if df is not None and not df.empty: frames.append(df)
        except Exception as e:
            debug_log.append(f"news(stock_id,start/end) error: {e}")

    # 2) keyword + start/end
    if keyword:
        try:
            df = api.taiwan_stock_news(keyword=keyword, start_date=start_date, end_date=end_date)
            debug_log.append(f"news(keyword,start/end): {len(df) if df is not None else 'None'}")
            if df is not None and not df.empty: frames.append(df)
        except Exception as e:
            debug_log.append(f"news(keyword,start/end) error: {e}")

    # 3) å–®æ—¥æƒæï¼ˆè¿‘å¹¾å¤©é€æ—¥ï¼‰
    try:
        days = 5
        for i in range(days):
            d = (datetime.now() - timedelta(days=i)).strftime("%Y-%m-%d")
            try:
                if code:
                    df = api.taiwan_stock_news(stock_id=code, date=d)
                    if df is not None and not df.empty: frames.append(df)
                if keyword:
                    dfk = api.taiwan_stock_news(keyword=keyword, date=d)
                    if dfk is not None and not dfk.empty: frames.append(dfk)
            except Exception:
                pass
        debug_log.append(f"news(daily sweep frames): {sum(len(f) for f in frames) if frames else 0}")
    except Exception as e:
        debug_log.append(f"news(daily sweep) error: {e}")

    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ===== FinMind æŠ“å…¬å‘Šï¼ˆå¤šå‡½å¼åå®¹éŒ¯ï¼‰ =====
def _try_fetch_ann(code: Optional[str], keyword: Optional[str],
                   start_date: str, end_date: str, debug_log: list):
    import pandas as pd
    frames = []
    funcs = []
    for name in ["taiwan_stock_announcement", "taiwan_stock_announcements"]:
        f = getattr(api, name, None)
        if f: funcs.append(f)

    # 1) start/end
    for f in funcs:
        try:
            if code:
                df = f(stock_id=code, start_date=start_date, end_date=end_date)
                debug_log.append(f"{f.__name__}(stock_id,start/end): {len(df) if df is not None else 'None'}")
                if df is not None and not df.empty: frames.append(df)
            if keyword:
                df = f(keyword=keyword, start_date=start_date, end_date=end_date)
                debug_log.append(f"{f.__name__}(keyword,start/end): {len(df) if df is not None else 'None'}")
                if df is not None and not df.empty: frames.append(df)
        except Exception as e:
            debug_log.append(f"{f.__name__}(start/end) error: {e}")

    # 2) å–®æ—¥æƒæ
    for f in funcs:
        try:
            days = 5
            for i in range(days):
                d = (datetime.now() - timedelta(days=i)).strftime("%Y-%m-%d")
                try:
                    if code:
                        df = f(stock_id=code, date=d)
                        if df is not None and not df.empty: frames.append(df)
                    if keyword:
                        dfk = f(keyword=keyword, date=d)
                        if dfk is not None and not dfk.empty: frames.append(dfk)
                except Exception:
                    pass
            debug_log.append(f"{f.__name__}(daily sweep frames): {sum(len(fm) for fm in frames) if frames else 0}")
        except Exception as e:
            debug_log.append(f"{f.__name__}(daily sweep) error: {e}")

    if frames:
        return pd.concat(frames, ignore_index=True)
    return pd.DataFrame()

# ===== APIï¼šå³æ™‚æ–°èï¼å…¬å‘Šï¼ˆFinMind + RSS å‚™æ´ï¼‰ =====
@app.get("/api/events")
@login_required
def api_events():
    """
    /api/events?query=2330&hours=48&limit=50
    /api/events?query=å°ç©é›»
    FinMind æŠ“ä¸åˆ° â†’ è‡ªå‹•ç”¨ Google News RSS å‚™æ´
    """
    q = request.args.get("query", "").strip()
    hours = int(request.args.get("hours", "48"))
    limit = int(request.args.get("limit", "50"))
    if not q:
        return jsonify(success=False, message="è«‹æä¾› queryï¼ˆè‚¡ç¥¨ä»£ç¢¼æˆ–é—œéµå­—ï¼‰"), 400

    debug_log = []
    is_code = q.isdigit()
    code = q if is_code else None
    keyword = _maybe_get_name_by_code(q) if is_code else q

    since_dt = datetime.now() - timedelta(hours=hours)
    start_date = since_dt.strftime("%Y-%m-%d")
    end_date = datetime.now().strftime("%Y-%m-%d")

    items = []

    # ---- FinMind æ–°è ----
    try:
        df_news = _try_fetch_news(code, keyword, start_date, end_date, debug_log)
        if df_news is not None and not df_news.empty:
            for _, r in df_news.iterrows():
                title = str(r.get("title") or r.get("news_title") or "")
                src = str(r.get("source") or r.get("media") or "æ–°è")
                url = str(r.get("url") or r.get("link") or "")
                dt = str(r.get("date") or r.get("time") or end_date)
                if dt >= start_date and title:
                    items.append({
                        "type": "news",
                        "title": title,
                        "source": src,
                        "time": dt,
                        "url": url,
                        "risk": _label_risk(title),
                    })
        else:
            debug_log.append("FinMind news empty")
    except Exception as e:
        debug_log.append(f"news total error: {e}")

    # ---- FinMind å…¬å‘Š ----
    try:
        df_ann = _try_fetch_ann(code, keyword, start_date, end_date, debug_log)
        if df_ann is not None and not df_ann.empty:
            for _, r in df_ann.iterrows():
                title = str(r.get("title") or r.get("subject") or "")
                url = str(r.get("url") or r.get("link") or "")
                dt = str(r.get("date") or r.get("time") or end_date)
                if dt >= start_date and title:
                    items.append({
                        "type": "announcement",
                        "title": title,
                        "source": "å…¬é–‹è³‡è¨Šè§€æ¸¬ç«™",
                        "time": dt,
                        "url": url,
                        "risk": _label_risk(title),
                    })
        else:
            debug_log.append("FinMind announcements empty")
    except Exception as e:
        debug_log.append(f"ann total error: {e}")

    # ---- FinMind å®Œå…¨æŠ“ä¸åˆ° â†’ RSS å‚™æ´ ----
    if not items:
        rss_kw = (keyword or q).strip()
        rss_items = _fetch_google_news_rss(rss_kw, hours=hours, limit=limit)
        debug_log.append(f"RSS items: {len(rss_items)}")
        items.extend(rss_items)

    # ---- å»é‡ + æ’åº ----
    seen = set()
    dedup = []
    for it in items:
        key = (it.get("title","").strip().lower(), (it.get("source","") or "").strip().lower())
        if key in seen:
            continue
        seen.add(key)
        dedup.append(it)

    # FinMind çš„ time å¤šç‚º YYYY-MM-DDï¼Œå¯å­—ä¸²æ’åºï¼›RSS time å¯èƒ½ç„¡æ³•å¯é æ’åº
    dedup.sort(key=lambda x: x.get("time", ""), reverse=True)

    return jsonify(
        success=True,
        query=q,
        items=dedup[:limit],
        window_hours=hours,
        debug=debug_log
    )


# =====================================================
# ğŸ§  AI Insightï¼šäº‹ä»¶åˆ†æ + ä¸²æµç‰ˆï¼ˆæ•´åˆå®Œæˆï¼‰
# =====================================================

# ====== é€Ÿåº¦å„ªåŒ–èˆ‡é¸å–ç­–ç•¥å·¥å…· ======
from functools import lru_cache
from concurrent.futures import ThreadPoolExecutor, as_completed
from statistics import median
import json, math, re
from flask import Response, stream_with_context

@lru_cache(maxsize=256)
def _cached_ai_eval(text: str) -> dict:
    return _ai_eval_one_event(text)

def _hours_ago(dt_str: str) -> float:
    try:
        try:
            dt = datetime.fromisoformat(dt_str)
        except:
            from email.utils import parsedate_to_datetime
            dt = parsedate_to_datetime(dt_str).astimezone(tz=None).replace(tzinfo=None)
        return max((datetime.now() - dt).total_seconds() / 3600.0, 0.0)
    except:
        return 0.0

def _time_decay(hours_ago: float, tau: float = 48.0) -> float:
    return math.exp(-float(hours_ago) / tau)

def _norm_title(t: str) -> str:
    t = (t or "").lower()
    t = re.sub(r"[^\w\s\u4e00-\u9fff]", " ", t)
    return re.sub(r"\s+", " ", t).strip()

def _jaccard(a: str, b: str) -> float:
    sa, sb = set(_norm_title(a).split()), set(_norm_title(b).split())
    if not sa or not sb: return 0.0
    return len(sa & sb) / len(sa | sb)

def _pick_diverse(items: list, k: int = 3, same_src_limit: int = 1,
                  lambda_div: float = 0.6, sim_th: float = 0.6):
    chosen, src_cnt = [], {}
    cand = sorted(items, key=lambda x: x['base_score'], reverse=True)
    while cand and len(chosen) < k:
      best_i, best_val = -1, -1e9
      for idx, it in enumerate(cand):
        src = (it.get("source") or "").strip().lower()
        if src_cnt.get(src, 0) >= same_src_limit:
          continue
        max_sim = max((_jaccard(it['title'], c['title']) for c in chosen), default=0.0)
        if max_sim >= sim_th:
          continue
        mmr = it['base_score'] - lambda_div * max_sim
        if mmr > best_val:
          best_val, best_i = mmr, idx
      if best_i < 0: break
      pick = cand.pop(best_i)
      s = (pick.get("source") or "").strip().lower()
      src_cnt[s] = src_cnt.get(s, 0) + 1
      chosen.append(pick)
    return chosen


# =====================================================
# /api/ai/insightï¼ˆä¸»åˆ†æç«¯é»ï¼‰
# =====================================================
@app.get("/api/ai/insight")
@login_required
def api_ai_insight_addon():
    q = request.args.get("query", "").strip()
    hours = int(request.args.get("hours", "48"))
    limit = int(request.args.get("limit", "50"))
    if not q:
        return jsonify(success=False, message="è«‹æä¾› queryï¼ˆè‚¡ç¥¨ä»£ç¢¼æˆ–é—œéµå­—ï¼‰"), 400

    items, debug_log = _collect_events_for_ai(q, hours=hours, limit=min(limit, 50))
    if not items:
        return jsonify(success=True, query=q, stock_score=0.0, items=[], top_items=[], risk_temp=0.0, uncertainty=1.0, n_events=0, debug=debug_log)

    N = min(30, len(items))
    analyzed = []
    with ThreadPoolExecutor(max_workers=6) as ex:
        future_map = {}
        for ev in items[:N]:
            text = f"{ev.get('title','')}ï¼ˆä¾†æº:{ev.get('source','')} æ™‚é–“:{ev.get('time','')}ï¼‰"
            future_map[ex.submit(_cached_ai_eval, text)] = ev

        for fut in as_completed(future_map):
            ev = future_map[fut]
            try:
                info = fut.result()
            except Exception:
                info = _ai_rule_eval_basic(ev.get('title',''))
            ev_score = _ai_event_score(info)
            analyzed.append({**ev, **info, "event_score": ev_score})

    for ev in items[N:]:
        analyzed.append({**ev, "direction": 0, "severity": 1, "confidence": 0.2, "horizon": "çŸ­", "why": "æœªç´å…¥AIè©•åˆ†ï¼ˆç‚ºäº†é€Ÿåº¦ï¼‰", "event_score": 0.0})

    for ev in analyzed:
        age_h = _hours_ago(ev.get("time", ""))
        decay = _time_decay(age_h)
        conf = float(ev.get("confidence", 0.5))
        ev["_base_score"] = abs(float(ev.get("event_score", 0.0))) * decay * (0.6 + 0.4 * conf)

    scores = sorted([float(x["event_score"]) for x in analyzed])
    n = len(scores)
    if n >= 5:
        cut = max(1, int(n * 0.15))
        trimmed = scores[cut:-cut] if (n - 2 * cut) >= 1 else scores
    else:
        trimmed = scores
    stock_score = sum(trimmed) / len(trimmed) if trimmed else 0.0

    avg_conf = sum(float(x.get("confidence", 0.5)) for x in analyzed) / max(len(analyzed), 1)
    dispersion = (median(abs(s - stock_score) for s in scores) if scores else 0.0)
    uncertainty = min(1.0, (1.0 - avg_conf) * (1.0 + min(abs(dispersion) / 3.0, 1.0)))
    risk_temp = sum(abs(float(x["event_score"])) for x in analyzed if float(x["event_score"]) < 0)

    pos = [{**e, "base_score": e["_base_score"]} for e in analyzed if int(e.get("direction", 0)) > 0]
    neg = [{**e, "base_score": e["_base_score"]} for e in analyzed if int(e.get("direction", 0)) < 0]
    latest = sorted(analyzed, key=lambda x: x.get("time", ""), reverse=True)[:1]
    top_items = (_pick_diverse(pos, k=2) + _pick_diverse(neg, k=2) + latest)[:5]

    return jsonify(
        success=True,
        query=q,
        stock_score=round(stock_score, 3),
        items=analyzed,
        top_items=top_items,
        risk_temp=round(risk_temp, 2),
        uncertainty=round(uncertainty, 2),
        n_events=len(analyzed),
        debug=debug_log
    )


# =====================================================
# /api/ai/insight/streamï¼ˆä¸²æµç‰ˆï¼‰
# =====================================================
def _sse(event: str, data: dict) -> str:
    return f"event: {event}\ndata: {json.dumps(data, ensure_ascii=False)}\n\n"

@app.get("/api/ai/insight/stream")
@login_required
def api_ai_insight_stream():
    q = request.args.get("query", "").strip()
    hours = int(request.args.get("hours", "48"))
    limit = int(request.args.get("limit", "50"))
    if not q:
        return jsonify(success=False, message="ç¼ºå°‘ query"), 400

    def gen():
        items, _ = _collect_events_for_ai(q, hours=hours, limit=min(limit, 50))
        yield _sse("events", {"count": len(items)})

        if not items:
            yield _sse("summary", {"success": True, "stock_score": 0.0, "top_items": [], "uncertainty": 1.0, "risk_temp": 0.0, "n_events": 0})
            yield _sse("done", {})
            return

        yield _sse("list", {"items": items[:min(10, len(items))]})

        N = min(30, len(items))
        analyzed = []
        with ThreadPoolExecutor(max_workers=6) as ex:
            future_map = {}
            for idx, ev in enumerate(items[:N]):
                text = f"{ev.get('title','')}ï¼ˆä¾†æº:{ev.get('source','')} æ™‚é–“:{ev.get('time','')}ï¼‰"
                future_map[ex.submit(_cached_ai_eval, text)] = (idx, ev)

            for fut in as_completed(future_map):
                idx, ev = future_map[fut]
                try:
                    info = fut.result()
                except Exception:
                    info = _ai_rule_eval_basic(ev.get('title',''))
                ev_score = _ai_event_score(info)
                enr = {**ev, **info, "event_score": ev_score}
                analyzed.append(enr)
                yield _sse("item", {"index": idx, "item": enr})

        for ev in items[N:]:
            analyzed.append({**ev, "direction": 0, "severity": 1, "confidence": 0.2, "horizon": "çŸ­", "why": "æœªç´å…¥AIè©•åˆ†ï¼ˆé€Ÿåº¦å„ªåŒ–ï¼‰", "event_score": 0.0})

        for ev in analyzed:
            age = _hours_ago(ev.get("time", ""))
            decay = _time_decay(age)
            conf = float(ev.get("confidence", 0.5))
            ev["_base_score"] = abs(float(ev.get("event_score", 0.0))) * decay * (0.6 + 0.4 * conf)

        scores = sorted([float(x["event_score"]) for x in analyzed])
        n = len(scores)
        if n >= 5:
            cut = max(1, int(n * 0.15))
            trimmed = scores[cut:-cut] if (n - 2 * cut) >= 1 else scores
        else:
            trimmed = scores
        stock_score = sum(trimmed) / len(trimmed) if trimmed else 0.0

        avg_conf = sum(float(x.get("confidence", 0.5)) for x in analyzed) / max(len(analyzed), 1)
        dispersion = (median(abs(s - stock_score) for s in scores) if scores else 0.0)
        uncertainty = min(1.0, (1.0 - avg_conf) * (1.0 + min(abs(dispersion) / 3.0, 1.0)))
        risk_temp = sum(abs(float(x["event_score"])) for x in analyzed if float(x["event_score"]) < 0)

        pos = [{**e, "base_score": e["_base_score"]} for e in analyzed if int(e.get("direction", 0)) > 0]
        neg = [{**e, "base_score": e["_base_score"]} for e in analyzed if int(e.get("direction", 0)) < 0]
        latest = sorted(analyzed, key=lambda x: x.get("time", ""), reverse=True)[:1]
        top_items = (_pick_diverse(pos, k=2) + _pick_diverse(neg, k=2) + latest)[:5]

        yield _sse("summary", {
            "success": True,
            "query": q,
            "stock_score": round(stock_score, 3),
            "uncertainty": round(uncertainty, 2),
            "risk_temp": round(risk_temp, 2),
            "n_events": len(analyzed),
            "top_items": top_items
        })
        yield _sse("done", {})

    resp = Response(stream_with_context(gen()), mimetype="text/event-stream")
    resp.headers["Cache-Control"] = "no-cache"
    resp.headers["X-Accel-Buffering"] = "no"
    return resp






if __name__ == "__main__":
    with app.app_context():
        db.create_all()
    
    port = int(os.environ.get("PORT", 8000))  # Railway æœƒè‡ªå‹•è¨­å®š PORT ç’°å¢ƒè®Šæ•¸
    app.run(host="0.0.0.0", port=port, debug=True)  # å…è¨±å¤–éƒ¨è¨ªå•

